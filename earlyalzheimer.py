# -*- coding: utf-8 -*-
"""EarlyAlzheimer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1raSslmwls2Exa4IB2GuU5XBCpykUv6kr
"""

from google.colab import drive

drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
import seaborn as sn

dataset = pd.read_csv('/content/drive/MyDrive/kaggle_dataset/Detecting Early Alzheimer/oasis_longitudinal.csv')
print('import done')

dataset.head()

dataset.shape

dataset.info()

"""## Drop unnecessary columns"""

dataset = dataset.drop(['Hand'], axis=1)

"""## Replace variable to Detect variable"""

dataset['Group'] = dataset['Group'].replace(['Converted'], ['Demented'])

"""## Splitting dataset by dependencies"""

X = dataset.drop(['Group'],axis=1)
Y = dataset['Group']

"""## Finding missing value"""

dataset_missing = X.isna()
dataset_missing.head()

dataset_missing.dtypes

dataset_num_missing = dataset_missing.sum()
dataset_num_missing

dataset_num_missing / len(dataset)

"""## Impute missing value By KNN"""

from sklearn.impute import KNNImputer
knnimp = KNNImputer(n_neighbors = 5)

num = [col for col in X.columns if dataset[col].dtypes != 'O']

X[num].head()

knnimp.fit(X[num])

X[num]  = knnimp.transform(X[num])

X.isna().sum()

"""## Feature Encoding"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

le.fit(Y)

le.classes_

Y = le.transform(Y)

obj = [col for col in X.columns if dataset[col].dtypes == 'O']
X[obj]

le1 = LabelEncoder()
le1.fit(X['Subject ID'])
X['Subject ID'] = le1.transform(X['Subject ID'])

le2 = LabelEncoder()
le2.fit(X['MRI ID'])
X['MRI ID'] = le2.transform(X['MRI ID'])

le3 = LabelEncoder()
le3.fit(X['M/F'])
X['M/F'] = le3.transform(X['M/F'])

Y

"""## Feature transformation or Scalling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

X

"""## Handling Imbalanced Dataset"""

count_classes = pd.value_counts(dataset['Group'])
count_classes.plot(kind = 'bar', rot = 0)
plt.title("Rating")
plt.xticks(range(3))
plt.xlabel("Group")
plt.ylabel("No of patients")

nondemented = Y[Y== 1]
demented = Y[Y== 0]

print(nondemented.shape, demented.shape)

"""## SMOTE Sampling"""

from imblearn.combine import SMOTETomek
smk = SMOTETomek(random_state = 10)

X,Y = smk.fit_resample(X,Y)

X.shape,Y.shape

"""## Over Sampling"""

from imblearn.over_sampling import RandomOverSampler
os = RandomOverSampler(ratio = 1)

XS,Ys = os.fit_sample(X,Y)

XS.shape, Ys.shape

"""## Feature Correlation and Dimension Reduction(LDA)"""

from sklearn.preprocessing import Normalizer
X = Normalizer().fit_transform(X)
X = pd.DataFrame(X)

import seaborn as sns
plt.figure(figsize=(10,6))
cor = X.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)
plt.show()

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
lda = LDA(n_components =-1 )
X = lda.fit_transform(X,Y)

"""## Splitting dataset into training set and test set"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)

"""## Import libraries and Function"""

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import classification_report
from sklearn.metrics import recall_score
import seaborn as sns

def cvresult(y,pred):
  print('Cross Val f1 score : ',f1_score(y,pred))
  print('Cross Val Precision : ',precision_score(y,pred))
  print('Cross Val recall : ',recall_score(y,pred))
  print('Cross Val Classification Report : \n',classification_report(y,pred))

def result(y,p):
  print('Accuracy : ',accuracy_score(y,p))
  print('f1 score : ',f1_score(y,p))
  print('Precision : ',precision_score(y,p))
  print('recall : ',recall_score(y,p))
  print('Classification Report : \n',classification_report(y,p))

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import classification_report

"""## K-Fold Validation Import"""

from sklearn.model_selection import cross_val_score

"""## Import Classifier Model"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import  DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import ExtraTreeClassifier

"""# Hyper Parameter Tuning

###  Random search Grid search
"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV

"""### Linear Regression Random Search"""

rs = RandomizedSearchCV(LogisticRegression(solver='liblinear',multi_class='auto'),{ 'C' : [1,5,10]}, cv = 10,return_train_score=False, n_iter=2)
rs.fit(X,Y)
best_paramlr = rs.best_params_
pd.DataFrame(rs.cv_results_)[['param_C','mean_test_score']]
print(best_paramlr)

"""###KNN Random Search"""

rs = RandomizedSearchCV(KNeighborsClassifier(), {
            'leaf_size' : [1,5,10,15,20,50],
            'n_neighbors' : [1,5,10,15],
            'p' : [1,2,3]
        })
rs.fit(X,Y)
best_paramknn = rs.best_params_
pd.DataFrame(rs.cv_results_)[['param_leaf_size','param_n_neighbors','param_p','mean_test_score']]
print(best_paramknn)

"""### SVM Random Search"""

srs = RandomizedSearchCV(SVC(gamma='auto'),
            {
            'C' : [1,5,10,20,50],
            'kernel': ['rbf','linear']
        })
srs.fit(X,Y)
best_params = srs.best_params_
pd.DataFrame(srs.cv_results_)[['param_C','param_kernel','mean_test_score']]

"""### Naive Bayes Random Search"""

nbrs = RandomizedSearchCV(GaussianNB(),
            {
            'var_smoothing' : [0.3,0.4,0.5,0.6,0.7,0.8]
        })
nbrs.fit(X,Y)
best_paramnb = nbrs.best_params_
pd.DataFrame(nbrs.cv_results_)[['param_var_smoothing','mean_test_score']]
print(best_paramnb)

"""### Decision tree Random Search"""

dtrs = RandomizedSearchCV(DecisionTreeClassifier(),{
            'splitter':['best','random'],
            'max_depth' : [1,3,5],
            'min_samples_leaf':[1,2,3,4],
            'max_features':['auto','log2','sqrt',None],
            'max_leaf_nodes':[None,10,20,30,40,50]
        })
dtrs.fit(X,Y)
best_paramdt = dtrs.best_params_
pd.DataFrame(dtrs.cv_results_)[['param_splitter','param_max_depth','param_min_samples_leaf','param_max_features','param_max_leaf_nodes','mean_test_score']]

"""### Random Forest Random Search"""

rfrs = RandomizedSearchCV(RandomForestClassifier(),{
            'bootstrap': [True],
            'max_depth': [i for i in range(1,20,1)],
            'max_features': ['auto', 'log2','sqrt'],
            'min_samples_split':[i for i in range(1,50,1)],
            'n_estimators': [i for i in range(1,50,1)]
        })
rfrs.fit(X,Y)
best_paramrf = rfrs.best_params_
pd.DataFrame(rfrs.cv_results_)[['param_bootstrap','param_max_depth','param_max_features','param_n_estimators','mean_test_score']]

"""### Extra Tree Random Search"""

etrs = RandomizedSearchCV(ExtraTreeClassifier(),{
            'criterion': ['gini','entropy'],
            'max_depth': [i for i in range(1,50,1)],
            'max_features': ['auto', 'log2','sqrt']
        })
etrs.fit(X,Y)
best_paramet = etrs.best_params_
pd.DataFrame(etrs.cv_results_)[['param_criterion','param_max_depth','param_max_features',
                              'mean_test_score']]

"""# Find best parameters"""

model_params = {
    'logistic_regression' :{
        'model': LogisticRegression(solver='liblinear',multi_class='auto'),
        'params': {
            'C' : [1,5,10,20,50]
        }
    },
    'KNN' :{
        'model': KNeighborsClassifier(),
        'params': {
            'leaf_size' : [1,5,10,15,20,50],
            'n_neighbors' : [1,5,10,15],
            'p' : [1,2,3]
        }
    },
    'SVM' :{
        'model': SVC(gamma='auto'),
        'params': {
            'C' : [1,5,10,20,50],
            'kernel': ['rbf','linear']
        }
    },
    'Naive Bayes' :{
        'model': GaussianNB(),
        'params': {
            'var_smoothing' : [0.01,0.02,0.026,0.0265,0.0258,0.03]
        }
    },
    'Decision Tree' :{
        'model': DecisionTreeClassifier(),
        'params': {
            'splitter':['best','random'],
            'max_depth' : [1,3,5],
            'min_samples_leaf':[1,2,3,4,5],
            'max_features':['auto','log2','sqrt',None],
            'max_leaf_nodes':[None,10,20,30,40,50,60,70,80,90]
        }
    },
    'Random Forest' :{
        'model': RandomForestClassifier(),
        'params': {
            'bootstrap': [True],
            'max_depth': [5, 10, None],
            'max_features': ['auto', 'log2'],
            'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]
        }
    }
}

scores = []
for model_name,mp in model_params.items():
  clf= GridSearchCV(mp['model'],mp['params'],cv=10, return_train_score=False)
  clf.fit(X_train,Y_train)
  scores.append({
      'model' : model_name,
      'best_score' : clf.best_score_,
      'best_params' : clf.best_params_

  })

df = pd.DataFrame(scores, columns=['model','best_score','best_params'])
df

"""# Traditional Algorithm

##Logistic Regression
"""

classifier = LogisticRegression(random_state=42,C=best_paramlr['C'])
classifier.fit(X, Y)

r_prob = [0 for _ in range(len(Y_test))]

Y_predlr = classifier.predict(X_test)

ytest_pred = classifier.predict_proba(X_test)
lr_prob = classifier.predict_proba(X_test)

Y_cvpredlr = cross_val_predict(classifier, X, Y, cv=10)

cm = confusion_matrix(Y_test,Y_predlr)
print(cm)

cm = confusion_matrix(Y,Y_cvpredlr)
print(cm)

labels = ["{0:0.0f}".format(value) for value in
                cm.flatten()]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(classifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredlr)

result(Y_test,Y_predlr)

lr_auc = roc_auc_score(Y_test,lr_prob[:,1])
print('roc-auc score :{}'.format(lr_auc))

"""##K-NN"""

import math
math.sqrt(len(Y_test))

kclassifier = KNeighborsClassifier(n_neighbors = best_paramknn['n_neighbors'],
                                   p=best_paramknn['p'],leaf_size=best_paramknn['leaf_size'])
kclassifier.fit(X,Y)

Y_predk = kclassifier.predict(X_test)

Y_cvpredk = cross_val_predict(kclassifier, X, Y, cv=10)

ytest_pred = kclassifier.predict_proba(X_test)
knn_prob = kclassifier.predict_proba(X_test)

cmk = confusion_matrix(Y_test,Y_predk)
print(cmk)

cmk = confusion_matrix(Y,Y_cvpredk)
print(cmk)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmk.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmk.flatten()/np.sum(cmk)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmk, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(kclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredk)

result(Y_test,Y_predk)

knn_auc = roc_auc_score(Y_test,knn_prob[:,1])
print('roc-auc score :{}'.format(knn_auc))

"""##SVM"""

sclassifier = SVC(kernel = best_params['kernel'],random_state = 42,C=best_params['C'], probability=True)
sclassifier.fit(X,Y)

Y_preds = sclassifier.predict(X_test)

ytest_pred = sclassifier.predict_proba(X_test)
svm_prob = sclassifier.predict_proba(X_test)

Y_cvpreds = cross_val_predict(sclassifier, X, Y, cv=10)

cms = confusion_matrix(Y_test,Y_preds)
print(cms)

cms = confusion_matrix(Y,Y_cvpreds)
print(cms)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cms.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cms.flatten()/np.sum(cms)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cms, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(sclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpreds)

result(Y_test,Y_preds)

svm_auc = roc_auc_score(Y_test,svm_prob[:,1])
print('roc-auc score :{}'.format(svm_auc))

"""##kernel SVM"""

ksclassifier = SVC(kernel = 'linear',C=1,random_state = 0, probability=True)
ksclassifier.fit(X,Y)

Y_predks = ksclassifier.predict(X_test)

ytest_pred = ksclassifier.predict_proba(X_test)
 ksvm_prob = ksclassifier.predict_proba(X_test)

Y_cvpredks = cross_val_predict(ksclassifier, X, Y, cv=10)

cm = confusion_matrix(Y_test,Y_predks)
print(cm)

cmks = confusion_matrix(Y,Y_cvpredks)
print(cmks)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmks.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmks.flatten()/np.sum(cmks)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmks, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(ksclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredks)

result(Y_test,Y_predks)

ksvm_auc = roc_auc_score(Y_test,ksvm_prob[:,1])
print('roc-auc score :{}'.format(ksvm_auc))

"""## Naive Bays"""

nbclassifier = GaussianNB(var_smoothing=best_paramnb['var_smoothing'])
nbclassifier.fit(X,Y)

Y_prednb = nbclassifier.predict(X_test)

ytest_pred = nbclassifier.predict_proba(X_test)
nb_prob = nbclassifier.predict_proba(X_test)

Y_cvprednb = cross_val_predict(nbclassifier,X,Y,cv = 10)

cms = confusion_matrix(Y_test,Y_prednb)
print(cms)

cvcms = confusion_matrix(Y, Y_cvprednb)
print(cvcms)

labels = ["{0:0.0f}".format(value) for value in
                cvcms.flatten()]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cvcms, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(nbclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvprednb)

result(Y_test,Y_prednb)

nb_auc = roc_auc_score(Y_test,nb_prob[:,1])
print('roc-auc score :{}'.format(nb_auc))

"""## Decision Tree"""

dtclassifier = DecisionTreeClassifier(splitter=best_paramdt['splitter'],max_depth=best_paramdt['max_depth'],
                                      min_samples_leaf=best_paramdt['min_samples_leaf'],max_features=best_paramdt['max_features'],
                                      max_leaf_nodes=best_paramdt['max_leaf_nodes'])
dtclassifier.fit(X,Y)

Y_preddt = dtclassifier.predict(X_test)

ytest_pred = dtclassifier.predict_proba(X_test)
dt_prob = dtclassifier.predict_proba(X_test)

Y_cvpreddt = cross_val_predict(dtclassifier,X,Y,cv = 10)

cms = confusion_matrix(Y_test,Y_preddt)
print(cms)

cvcmsdt = confusion_matrix(Y, Y_cvpreddt)
print(cvcmsdt)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cvcmsdt.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cvcmsdt.flatten()/np.sum(cvcmsdt)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cvcmsdt, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(dtclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpreddt)

result(Y_test,Y_preddt)

dt_auc = roc_auc_score(Y_test,dt_prob[:,1])
print('roc-auc score :{}'.format(dt_auc))

"""## Random forest"""

rfclassifier = RandomForestClassifier(n_estimators = best_paramrf['n_estimators'],bootstrap=best_paramrf['bootstrap'],
                                      max_depth=best_paramrf['max_depth'], min_samples_split=best_paramrf['min_samples_split'],
                                      max_features=best_paramrf['max_features'], random_state = 42)
rfclassifier.fit(X,Y)

Y_predrf = rfclassifier.predict(X_test)

ytest_pred = rfclassifier.predict_proba(X_test)
rf_prob = rfclassifier.predict_proba(X_test)

Y_cvpredrf = cross_val_predict(rfclassifier,X,Y,cv = 10)

cms = confusion_matrix(Y_test,Y_predrf)
print(cms)

cvcmsrf = confusion_matrix(Y, Y_cvpredrf)
print(cvcmsrf)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cvcmsrf.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cvcmsrf.flatten()/np.sum(cvcmsrf)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cvcmsrf, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(rfclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredrf)

result(Y_test,Y_predrf)

rf_auc = roc_auc_score(Y_test,rf_prob[:,1])
print('roc-auc score :{}'.format(rf_auc))

"""## Extra Tree"""

etclassifier = ExtraTreeClassifier(criterion=best_paramet['criterion'],max_depth=best_paramet['max_depth'],
                                   max_features=best_paramet['max_features'],random_state=42)
etclassifier.fit(X,Y)

Y_predet = etclassifier.predict(X_test)

ytest_pred = etclassifier.predict_proba(X_test)
et_prob = etclassifier.predict_proba(X_test)

Y_cvpredet = cross_val_predict(etclassifier,X,Y,cv = 10)

cms = confusion_matrix(Y_test,Y_predet)
print(cms)

cvcmset = confusion_matrix(Y, Y_cvpredet)
print(cvcmset)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cvcmset.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cvcmset.flatten()/np.sum(cvcmset)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cvcmset, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(etclassifier,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredet)

result(Y_test,Y_predet)

et_auc = roc_auc_score(Y_test,et_prob[:,1])
print('roc-auc score :{}'.format(et_auc))

"""## ROC-AUC Curve"""

pred = []
for model in [classifier, kclassifier, sclassifier, ksclassifier, nbclassifier, dtclassifier,rfclassifier] :
  pred.append(pd.Series(model.predict_proba(X_test)[:,1]))
final_prediction = pd.concat(pred,axis=1).mean(axis=1)
print('Final roc-auc score :{}'.format(roc_auc_score(Y_test,final_prediction)))

pd.concat(pred,axis=1)

final_prediction

fpr, tpr, thresholds = roc_curve(Y_test, final_prediction)
thresholds

from sklearn.metrics import accuracy_score
accuracy_ls=[]
for thres in thresholds:
  y_pred = np.where(final_prediction>thres,1,0)
  accuracy_ls.append(accuracy_score(Y_test,y_pred, normalize=True))
accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)], axis=1)
accuracy_ls.columns = ['Thresholds','Accuracy']
accuracy_ls.sort_values(by='Accuracy', ascending = False, inplace=True)
accuracy_ls.head()

def plot_roc_curve(fpr, tpr):
  plt.plot(fpr, tpr, color = 'red', label='ROC')
  plt.plot([0,1], [0,1], color= 'blue', linestyle='--' )
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('ROC CURVE')
  plt.legend()
  plt.show()

plot_roc_curve(fpr, tpr)

lr_fpr,lr_tpr,_ = roc_curve(Y_test,lr_prob[:,1])
svm_fpr,svm_tpr,_ = roc_curve(Y_test,svm_prob[:,1])
nb_fpr,nb_tpr,_ = roc_curve(Y_test,nb_prob[:,1])
dt_fpr,dt_tpr,_ = roc_curve(Y_test,dt_prob[:,1])
rf_fpr,rf_tpr,_ = roc_curve(Y_test,rf_prob[:,1])
et_fpr,et_tpr,_ = roc_curve(Y_test,et_prob[:,1])

plt.plot(lr_fpr, lr_tpr, color = 'red', linestyle='-',label='Logistric Regrassion AUROC = %0.3f'% lr_auc)
plt.plot(svm_fpr, svm_tpr, color = 'green', linestyle='-',label='SVM AUROC = %0.3f'% svm_auc)
plt.plot(nb_fpr, nb_tpr, color = 'orange', linestyle='-',label='Naive Bayes AUROC = %0.3f'% nb_auc)
plt.plot(dt_fpr, dt_tpr, color = 'blue', linestyle='-',label='Decision Tree  AUROC = %0.3f'% dt_auc)
plt.plot(rf_fpr, rf_tpr, color = 'cyan', linestyle='-',label='Random Forest AUROC = %0.3f'% rf_auc)
plt.plot(et_fpr, et_tpr, color = 'coral', linestyle='-',label='Extra Tree AUROC = %0.3f'% et_auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC CURVE (Traditional)')
plt.legend(loc=4, prop={'size': 12})
plt.show()

"""# K fold function"""

def Kfold_result(X,Y,model,foldnum):
   print("\ncross validation")
   from sklearn.model_selection import cross_val_score, cross_validate,cross_val_predict
   from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
   scoring = {'accuracy' : make_scorer(accuracy_score),
           'precision' : make_scorer(precision_score),
           'recall' : make_scorer(recall_score),
           'f1_score' : make_scorer(f1_score)}

   results = cross_validate(estimator=model,
                                          X=X,
                                          y=Y,
                                          cv=10,
                                          scoring=scoring)
   print('cross accuracy:',np.mean(results['test_accuracy']))
   print('cross precision:',np.mean(results['test_precision']))
   print('cross recall:',np.mean(results['test_recall']))
   print('cross f1 score:', np.mean(results['test_f1_score']))
   cross_pred_test = cross_val_predict(model,X,Y,cv = 10)
   cm = confusion_matrix(Y,cross_pred_test)
   group_names = ['','','','']
   group_counts = ["{0:0.0f}".format(value) for value in
                cm.flatten()]
   group_percentages = ["{0:.2%}".format(value) for value in
                     cm.flatten()/np.sum(cm)]
   labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
   labels = np.asarray(labels).reshape(2,2)
   sns.heatmap(cm, annot=labels, fmt='', cmap='Purples')

   pass

"""# Stacking"""

from sklearn.ensemble import StackingClassifier

estimators = [('SVM', sclassifier), ('RF', rfclassifier)]
stackclassifier = StackingClassifier(estimators=estimators)

Kfold_result(X,Y,stackclassifier,10)

# AUC
from sklearn.metrics import roc_auc_score, roc_curve
stackclassifier.fit(X,Y)
st_probs_y = stackclassifier.predict_proba(X)
st_auc_y = roc_auc_score(Y, st_probs_y[:,1])
st_fpr, st_tpr, threshold = roc_curve(Y,st_probs_y[:,1])
print(st_auc_y)

from sklearn.metrics import roc_auc_score,roc_curve

plt.figure(figsize=(5,5),dpi = 100)
plt.plot(st_fpr,st_tpr,linestyle='-',label='Stacking(ROC:%0.3f)' % st_auc_y)
lw=2
plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate ---->")
plt.ylabel("True Positive Rate ---->")
plt.legend()
plt.show()

"""#Hard Ensemble"""

from sklearn.ensemble import VotingClassifier
eclfh = VotingClassifier(estimators=[('LRmodel', classifier), ('SVM', sclassifier), ('RF', rfclassifier)],voting='hard')

for clf, label in zip([classifier, sclassifier, rfclassifier, eclfh], ['LR Classifier', 'SVM', 'RF', 'Ensemble_hard']):
      scores = cross_val_score(clf, X, Y, scoring='accuracy', cv=10)
      print("Accuracy: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))
for clf, label in zip([classifier, sclassifier, rfclassifier, eclfh], ['LR Classifier', 'SVM', 'RF', 'Ensemble']):
      scores = cross_val_score(clf, X, Y, scoring='precision', cv=10)
      print("Precision: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))
for clf, label in zip([classifier, sclassifier, rfclassifier, eclfh], ['LR Classifier', 'SVM', 'RF', 'Ensemble']):
      scores = cross_val_score(clf, X, Y, scoring='recall', cv=10)
      print("Recall: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))

"""# Soft ensemble"""

from sklearn.ensemble import VotingClassifier
eclfs = VotingClassifier(estimators=[('LR', classifier), ('SVM', sclassifier), ('RF', rfclassifier)],voting='soft')

for clf, label in zip([classifier, sclassifier, rfclassifier, eclfs], ['LR', 'SVM', 'RF', 'Ensemble_soft']):
      scores = cross_val_score(clf, X, Y, scoring='accuracy', cv=10)
      print("Accuracy: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))
for clf, label in zip([classifier, sclassifier, rfclassifier, eclfs], ['LR', 'SVM', 'RF', 'Ensemble_soft']):
      scores = cross_val_score(clf, X, Y, scoring='precision', cv=10)
      print("Precision: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))
for clf, label in zip([classifier, sclassifier, rfclassifier, eclfs], ['LR', 'SVM', 'RF', 'Ensemble_soft']):
      scores = cross_val_score(clf, X, Y, scoring='recall', cv=10)
      print("Recall: %0.4f (+/- %0.3f) [%s]" % (scores.mean(), scores.std(), label))

Kfold_result(X,Y,eclfs,10)

# AUC
from sklearn.metrics import roc_auc_score, roc_curve
eclfs.fit(X,Y)
es_probs_y = eclfs.predict_proba(X)
es_auc_y = roc_auc_score(Y, es_probs_y[:,1])
es_fpr, es_tpr, threshold = roc_curve(Y,es_probs_y[:,1])
print(es_auc_y)

from sklearn.metrics import roc_auc_score,roc_curve


plt.figure(figsize=(5,5),dpi = 100)
plt.plot(es_fpr,es_tpr,linestyle='-',label='Soft Voting(ROC:%0.3f)' % es_auc_y)
lw=2
plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate ---->")
plt.ylabel("True Positive Rate ---->")
plt.legend()
plt.show()

"""# ROC"""

lr_fpr,lr_tpr,_ = roc_curve(Y_test,lr_prob[:,1])
svm_fpr,svm_tpr,_ = roc_curve(Y_test,svm_prob[:,1])
nb_fpr,nb_tpr,_ = roc_curve(Y_test,nb_prob[:,1])
dt_fpr,dt_tpr,_ = roc_curve(Y_test,dt_prob[:,1])
rf_fpr,rf_tpr,_ = roc_curve(Y_test,rf_prob[:,1])
et_fpr,et_tpr,_ = roc_curve(Y_test,et_prob[:,1])

plt.figure(figsize=(4,4),dpi = 100)
plt.plot(lr_fpr, lr_tpr, color = 'red', linestyle='-',label='Logistric Regrassion AUROC = %0.3f'% lr_auc)
plt.plot(svm_fpr, svm_tpr, color = 'green', linestyle='-',label='SVM AUROC = %0.3f'% svm_auc)
plt.plot(nb_fpr, nb_tpr, color = 'orange', linestyle='-',label='Naive Bayes AUROC = %0.3f'% nb_auc)
plt.plot(dt_fpr, dt_tpr, color = 'blue', linestyle='-',label='Decision Tree  AUROC = %0.3f'% dt_auc)
plt.plot(rf_fpr, rf_tpr, color = 'cyan', linestyle='-',label='Random Forest AUROC = %0.3f'% rf_auc)
plt.plot(et_fpr, et_tpr, color = 'coral', linestyle='-',label='Extra Tree AUROC = %0.3f'% et_auc)
plt.plot(es_fpr,es_tpr,linestyle='-',label='Voting AUROC = %0.3f' % es_auc_y)
plt.plot(st_fpr,st_tpr,color = 'purple', linestyle='-',label='Stacking AUROC = %0.3f' % st_auc_y)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC CURVE (Traditional)')
plt.legend(loc=4, prop={'size': 8.5})
plt.show()

"""# Bagging"""

from sklearn.ensemble import BaggingClassifier

"""## Hyper parameter Tuning

### Bagging Logistic Regression Random Search
"""

grs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [LogisticRegression(solver='liblinear',multi_class='auto')],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
grs.fit(X,Y)
best_paramgrs = grs.best_params_
pd.DataFrame(grs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""### Bagging KNN Random Search"""

kgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [KNeighborsClassifier()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
kgrs.fit(X_train,Y_train)
pd.DataFrame(kgrs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""### Bagging SVM Random Search"""

sgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [SVC()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
sgrs.fit(X,Y)
best_paramsgrs = sgrs.best_params_
pd.DataFrame(grs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]
print(best_paramsgrs)

"""### Bagging Naive Bayes Random Search"""

nbgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [GaussianNB()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
nbgrs.fit(X,Y)
best_paramnbgrs = nbgrs.best_params_
pd.DataFrame(nbgrs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""### Bagging Decision Tree Random Search"""

dtgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [DecisionTreeClassifier()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
dtgrs.fit(X,Y)
best_paramdtgrs = dtgrs.best_params_
pd.DataFrame(dtgrs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""### Bagging Random Forest Random Search"""

rfgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [RandomForestClassifier()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
rfgrs.fit(X,Y)
best_paramrfgrs = rfgrs.best_params_
pd.DataFrame(rfgrs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""### Bagging Extra Tree Random Search"""

etgrs = RandomizedSearchCV(BaggingClassifier(),{
    'base_estimator' : [ExtraTreeClassifier()],
    'bootstrap_features': ['True','False',None],
    'n_estimators' : [i for i in range(1,100,1)],
    'n_jobs' : [1,2,3,4,5]
})
etgrs.fit(X,Y)
best_parametgrs = etgrs.best_params_
pd.DataFrame(etgrs.cv_results_)[['param_bootstrap_features','param_n_estimators','param_n_jobs','mean_test_score']]

"""## Base estimator Logistric Regression"""

bag = BaggingClassifier(classifier,n_estimators= best_paramgrs['n_estimators'],bootstrap_features=best_paramgrs['bootstrap_features'],
                        n_jobs=best_paramgrs['n_jobs'],random_state=42)

bag.fit(X,Y)

Y_predbglr = bag.predict(X_test)

Y_cvpredbglr = cross_val_predict(bag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbglr)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbglr)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(bag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbglr)

result(Y_test,Y_predbglr)

lrbg_prob = bag.predict_proba(X_test)
lrbg_auc = roc_auc_score(Y_test,lrbg_prob[:,1])
print('roc-auc score :{}'.format(lrbg_auc))

"""## Base estimator K-NN"""

kbag = BaggingClassifier(kclassifier, n_estimators= 75,bootstrap_features=False,n_jobs=3)

kbag.fit(X_train,Y_train)

Y_predbgk = kbag.predict(X_test)

Y_cvpredbgk = cross_val_predict(kbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgk)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgk)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(kbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgk)

result(Y_test,Y_predbgk)

knnbg_prob = kbag.predict_proba(X_test)
knnbg_auc = roc_auc_score(Y_test,knnbg_prob[:,1])
print('roc-auc score :{}'.format(knnbg_auc))

"""## Base estimator SVM"""

sbag = BaggingClassifier(sclassifier, n_estimators= best_paramsgrs['n_estimators'],bootstrap_features=best_paramsgrs['bootstrap_features'],
                          n_jobs= best_paramsgrs['n_jobs'],random_state=42)

sbag.fit(X_train,Y_train)

Y_predbgs = sbag.predict(X_test)

Y_cvpredbgs = cross_val_predict(sbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgs)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgs)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(sbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgs)

result(Y_test,Y_predbgs)

svmbg_prob = sbag.predict_proba(X_test)
svmbg_auc = roc_auc_score(Y_test,svmbg_prob[:,1])
print('roc-auc score :{}'.format(svmbg_auc))

"""## Base estimator kernal SVM"""

ksbag = BaggingClassifier(ksclassifier, n_estimators= 75,bootstrap_features=True,n_jobs=3)

ksbag.fit(X_train,Y_train)

Y_predbgks = ksbag.predict(X_test)

Y_cvpredbgks = cross_val_predict(ksbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgks)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgks)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(ksbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgks)

result(Y_test,Y_predks)

ksvmbg_prob = ksbag.predict_proba(X_test)
ksvmbg_auc = roc_auc_score(Y_test,ksvmbg_prob[:,1])
print('roc-auc score :{}'.format(ksvmbg_auc))

"""## Base estimator Naive Bayes"""

nbbag = BaggingClassifier(nbclassifier, n_estimators= best_paramnbgrs['n_estimators'],
                          bootstrap_features=best_paramnbgrs['bootstrap_features'],
                          n_jobs=best_paramnbgrs['n_jobs'],random_state=42)

nbbag.fit(X_train,Y_train)

Y_predbgnb = nbbag.predict(X_test)

Y_cvpredbgnb = cross_val_predict(nbbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgnb)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgnb)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(nbbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgnb)

result(Y_test,Y_predbgnb)

nbbg_prob = nbbag.predict_proba(X_test)
nbbg_auc = roc_auc_score(Y_test,nbbg_prob[:,1])
print('roc-auc score :{}'.format(nbbg_auc))

"""## Base estimator Decision Tree"""

dtbag = BaggingClassifier(dtclassifier, n_estimators= best_paramdtgrs['n_estimators'],bootstrap_features=best_paramdtgrs['bootstrap_features'],
                          n_jobs=best_paramdtgrs['n_jobs'],random_state =42)

dtbag.fit(X_train,Y_train)

Y_predbgdt = dtbag.predict(X_test)

Y_cvpredbgdt = cross_val_predict(dtbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgdt)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgdt)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(dtbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgdt)

result(Y_test,Y_predbgdt)

dtbg_prob = dtbag.predict_proba(X_test)
dtbg_auc = roc_auc_score(Y_test,dtbg_prob[:,1])
print('roc-auc score :{}'.format(dtbg_auc))

"""## Base estimator Random Forest"""

rfbag = BaggingClassifier(rfclassifier, n_estimators= best_paramrfgrs['n_estimators'],bootstrap_features=best_paramrfgrs['bootstrap_features'],
                          n_jobs=best_paramrfgrs['n_jobs'],random_state=42)

rfbag.fit(X_train,Y_train)

Y_predbgrf = rfbag.predict(X_test)

Y_cvpredbgrf = cross_val_predict(rfbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbgrf)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbgrf)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(rfbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbgrf)

result(Y_test,Y_predbgrf)

rfbg_prob = rfbag.predict_proba(X_test)
rfbg_auc = roc_auc_score(Y_test,rfbg_prob[:,1])
print('roc-auc score :{}'.format(rfbg_auc))

"""## Base estimator Extra Tree"""

etbag = BaggingClassifier(etclassifier, n_estimators= best_parametgrs['n_estimators'],
                          bootstrap_features=best_parametgrs['bootstrap_features'],n_jobs=best_parametgrs['n_jobs'],random_state=42)

etbag.fit(X_train,Y_train)

Y_predbget = etbag.predict(X_test)

Y_cvpredbget = cross_val_predict(etbag,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbget)
print(cm)

cmbg = confusion_matrix(Y,Y_cvpredbget)
print(cmbg)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbg.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbg.flatten()/np.sum(cmbg)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbg, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(etbag,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbget)

result(Y_test,Y_predbget)

etbg_prob = etbag.predict_proba(X_test)
etbg_auc = roc_auc_score(Y_test,etbg_prob[:,1])
print('roc-auc score :{}'.format(etbg_auc))

"""## ROC AUC CURVE  (Bagging)"""

lrg_fpr,lrg_tpr,_ = roc_curve(Y_test,lrbg_prob[:,1])
svmg_fpr,svmg_tpr,_ = roc_curve(Y_test,svmbg_prob[:,1])
nbg_fpr,nbg_tpr,_ = roc_curve(Y_test,nbbg_prob[:,1])
dtg_fpr,dtg_tpr,_ = roc_curve(Y_test,dtbg_prob[:,1])
rfg_fpr,rfg_tpr,_ = roc_curve(Y_test,rfbg_prob[:,1])
etg_fpr,etg_tpr,_ = roc_curve(Y_test,etbg_prob[:,1])

plt.plot(lrg_fpr, lrg_tpr, color = 'red', linestyle='-',label='Logistic Regrassion AUROC = %0.3f'% lrbg_auc)
plt.plot(svmg_fpr, svmg_tpr, color = 'green', linestyle='-',label='SVM AUROC = %0.3f'% svmbg_auc)
plt.plot(nbg_fpr, nbg_tpr, color = 'orange', linestyle='-',label='Naive Bayes AUROC = %0.3f'% nbbg_auc)
plt.plot(dtg_fpr, dtg_tpr, color = 'blue', linestyle='-',label='Decision Tree AUROC = %0.3f'% dtbg_auc)
plt.plot(rfg_fpr, rfg_tpr, color = 'cyan', linestyle='-',label='Random Forest AUROC = %0.3f'% rfbg_auc)
plt.plot(etg_fpr, etg_tpr, color = 'Coral', linestyle='-',label='Extra Tree AUROC = %0.3f'% etbg_auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC CURVE (BAGGING)')
plt.legend(loc=4, prop={'size': 12})
plt.show()

"""# Boosting"""

from sklearn.ensemble import AdaBoostClassifier

from sklearn.utils.testing import all_estimators

"""## Base estimator Logistric Regression"""

bs = AdaBoostClassifier(classifier,learning_rate=1, n_estimators=10, random_state=42)

bs.fit(X,Y)

Y_predbslr = bs.predict(X_test)

Y_cvpredbslr = cross_val_predict(bs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbslr)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbslr)
print(cmbs)

labels = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(bs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbslr)

result(Y_test,Y_predbslr)

lrbs_prob = bs.predict_proba(X_test)
lrbs_auc = roc_auc_score(Y_test,lrbs_prob[:,1])
print('roc-auc score :{}'.format(lrbs_auc))

"""## Base estimator K-NN"""

kbs = AdaBoostClassifier(kclassifier,learning_rate=1, n_estimators=10, random_state=None)

kbs.fit(X_train,Y_train)















"""## Base estimator SVM"""

sbs = AdaBoostClassifier(sclassifier,learning_rate=1, n_estimators=10, random_state=42)

sbs.fit(X,Y)

Y_predbss = sbs.predict(X_test)

Y_cvpredbss = cross_val_predict(sbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbss)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbss)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(sbs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbss)

result(Y_test,Y_predbss)

svmbs_prob = sbs.predict_proba(X_test)
svmbs_auc = roc_auc_score(Y_test,svmbs_prob[:,1])
print('roc-auc score :{}'.format(svmbs_auc))

"""## Base estimator Kernal SVM"""

ksbs = AdaBoostClassifier(ksclassifier,learning_rate=1, n_estimators=10, random_state=42)

ksbs.fit(X_train,Y_train)

Y_predbsks = ksbs.predict(X_test)

Y_cvpredbsks = cross_val_predict(ksbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbsks)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbsks)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(ksbs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbsks)

result(Y_test,Y_predbsks)

ksvmbs_prob = ksbs.predict_proba(X_test)
ksvmbs_auc = roc_auc_score(Y_test,ksvmbs_prob[:,1])
print('roc-auc score :{}'.format(ksvmbs_auc))

"""## Base estimator Naive Bays"""

nbbs = AdaBoostClassifier(nbclassifier,learning_rate=1, n_estimators=10, random_state=0)

nbbs.fit(X,Y)

Y_predbsnb = nbbs.predict(X_test)

Y_cvpredbsnb = cross_val_predict(nbbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbsnb)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbsnb)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(nbbs,X_train,Y_train, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbsnb)

result(Y_test,Y_predbsnb)

nbbs_prob = nbbs.predict_proba(X_test)
nbbs_auc = roc_auc_score(Y_test,nbbs_prob[:,1])
print('roc-auc score :{}'.format(nbbs_auc))

"""## Base estimator Decision Tree"""

dtbs = AdaBoostClassifier(dtclassifier,learning_rate=1, n_estimators=10, random_state=42)

dtbs.fit(X,Y)

Y_predbsdt = dtbs.predict(X_test)

Y_cvpredbsdt = cross_val_predict(dtbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbsdt)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbsdt)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(dtbs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbsdt)

result(Y_test,Y_predbsdt)

dtbs_prob = dtbs.predict_proba(X_test)
dtbs_auc = roc_auc_score(Y_test,dtbs_prob[:,1])
print('roc-auc score :{}'.format(dtbs_auc))

"""## Base estimator Random Rofest"""

rfbs = AdaBoostClassifier(rfclassifier,learning_rate=1, n_estimators=10, random_state=42)

rfbs.fit(X,Y)

Y_predbsrf = rfbs.predict(X_test)

Y_cvpredbsrf = cross_val_predict(rfbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbsrf)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbsrf)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(rfbs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbsrf)

result(Y_test,Y_predbsrf)

rfbs_prob = rfbs.predict_proba(X_test)
rfbs_auc = roc_auc_score(Y_test,rfbs_prob[:,1])
print('roc-auc score :{}'.format(rfbs_auc))

"""## Base estimator Extra Tree"""

etbs = AdaBoostClassifier(etclassifier,learning_rate=1, n_estimators=10, random_state=42)

etbs.fit(X,Y)

Y_predbset = etbs.predict(X_test)

Y_cvpredbset = cross_val_predict(etbs,X,Y,cv = 10)

cm = confusion_matrix(Y_test,Y_predbset)
print(cm)

cmbs = confusion_matrix(Y,Y_cvpredbset)
print(cmbs)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cmbs.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cmbs.flatten()/np.sum(cmbs)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cmbs, annot=labels, fmt='', cmap='Blues')

accuracy = cross_val_score(etbs,X,Y, cv=10, scoring='accuracy')
print('All Cross Val Accuracy :',accuracy)
print('\nCross Val Accuracy :',accuracy.mean())

cvresult(Y,Y_cvpredbset)

result(Y_test,Y_predbset)

etbs_prob = etbs.predict_proba(X_test)
etbs_auc = roc_auc_score(Y_test,etbs_prob[:,1])
print('roc-auc score :{}'.format(etbs_auc))

"""## ROC AUC CURVE  (Boosting)"""

lrs_fpr,lrs_tpr,_ = roc_curve(Y_test,lrbs_prob[:,1])
svms_fpr,svms_tpr,_ = roc_curve(Y_test,svmbs_prob[:,1])
nbs_fpr,nbs_tpr,_ = roc_curve(Y_test,nbbs_prob[:,1])
dts_fpr,dts_tpr,_ = roc_curve(Y_test,dtbs_prob[:,1])
rfs_fpr,rfs_tpr,_ = roc_curve(Y_test,rfbs_prob[:,1])
ets_fpr,ets_tpr,_ = roc_curve(Y_test,etbs_prob[:,1])

plt.plot(lrs_fpr, lrs_tpr, color = 'red', linestyle='-',label='Logistic Regression AUROC = %0.3f'% lrbs_auc)
plt.plot(svms_fpr, svms_tpr, color = 'green', linestyle='-',label='SVM AUROC = %0.3f'% svmbs_auc)
plt.plot(nbs_fpr, nbs_tpr, color = 'orange', linestyle='-',label='Naive Bayes AUROC = %0.3f'% nbbs_auc)
plt.plot(dts_fpr, dts_tpr, color = 'blue', linestyle='-',label='Decision Tree AUROC = %0.3f'% dtbs_auc)
plt.plot(rfs_fpr, rfs_tpr, color = 'cyan', linestyle='-',label='Random Rorest AUROC = %0.3f'% rfbs_auc)
plt.plot(ets_fpr, ets_tpr, color = 'Coral', linestyle='-',label='Extra Tree AUROC = %0.3f'% etbs_auc)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC CURVE (BOOSTING)')
plt.legend(loc=4, prop={'size': 12})
plt.show()